{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio import load\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _find_classes(self):\n",
    "        classes = [d.name for d in os.scandir(self.root) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(self.root, target_class)\n",
    "            for root_dir, _, file_names in os.walk(target_dir):\n",
    "                for file_name in file_names:\n",
    "                    if file_name.endswith('.wav') or file_name.endswith('.mp3') or file_name.endswith('.ogg'):\n",
    "                        file_path = os.path.join(root_dir, file_name)\n",
    "                        samples.append((file_path, class_index))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path, class_index = self.samples[idx]\n",
    "        # Load the audio file and preprocess\n",
    "        waveform, _ = load(audio_path)\n",
    "        waveform = self._preprocess_audio(waveform)\n",
    "        return waveform, class_index\n",
    "\n",
    "    def _preprocess_audio(self, waveform):\n",
    "        waveform = waveform.numpy()[0]  # Convert tensor to numpy array\n",
    "        max_len = 64600\n",
    "        if waveform.shape[0] >= max_len:\n",
    "            return waveform[:max_len]\n",
    "        else:\n",
    "            num_repeats = int(max_len / waveform.shape[0]) + 1\n",
    "            padded_waveform = np.tile(waveform, (1, num_repeats))[:, :max_len][0]\n",
    "            return padded_waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory where your data is stored\n",
    "root = \"/teamspace/studios/this_studio/SpeechAssign3/for-2seconds\"  # Replace this with the path to your data folder\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AudioDataset(root=os.path.join(root, \"training\"))\n",
    "test_dataset = AudioDataset(root=os.path.join(root, \"testing\"))\n",
    "validation_dataset = AudioDataset(root=os.path.join(root, \"validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (ssl_model): SSLModel(\n",
       "      (model): Wav2Vec2Model(\n",
       "        (feature_extractor): ConvFeatureExtractionModel(\n",
       "          (conv_layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (1-4): 4 x Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "            (5-6): 2 x Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU(approximate='none')\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "        (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "        (quantizer): GumbelVectorQuantizer(\n",
       "          (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "        )\n",
       "        (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (encoder): TransformerEncoder(\n",
       "          (pos_conv): Sequential(\n",
       "            (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "            (1): SamePad()\n",
       "            (2): GELU(approximate='none')\n",
       "          )\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (LL): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (first_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.5, inplace=True)\n",
       "    (drop_way): Dropout(p=0.2, inplace=True)\n",
       "    (selu): SELU(inplace=True)\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (GAT_layer_S): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (GAT_layer_T): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (pool_S): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_T): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Load the SSL W2V model trained for LA and DF tracks\n",
    "from model import Model\n",
    "\n",
    "model = Model(None, device=device)\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.load_state_dict(torch.load('/teamspace/studios/this_studio/final_model.pth'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 68/68 [00:23<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.3740133001730104\n",
      "EER: 0.5772058823525775\n",
      "Threshold at EER: 2.7146806716927294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Lists to store true labels and predicted scores\n",
    "true_labels = []\n",
    "predicted_scores = []\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Iterate through the test_loader to get true labels and predicted scores\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc=\"Testing\"):\n",
    "        # Assuming your model outputs probabilities or scores\n",
    "        output = model(data)\n",
    "        predicted_scores.extend(output[:, 1].cpu().numpy())  # Probability of positive class\n",
    "        true_labels.extend(target.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_scores = np.array(predicted_scores)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(true_labels, predicted_scores)\n",
    "\n",
    "# Calculate EER\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, predicted_scores, pos_label=1)\n",
    "eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "threshold = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "print(\"AUC:\", auc_score)\n",
    "print(\"EER:\", eer)\n",
    "print(\"Threshold at EER:\", threshold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
