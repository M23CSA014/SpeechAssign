{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manish/miniconda3/envs/speech/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchaudio import load\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.classes, self.class_to_idx = self._find_classes()\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _find_classes(self):\n",
    "        classes = [d.name for d in os.scandir(self.root) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_index = self.class_to_idx[target_class]\n",
    "            target_dir = os.path.join(self.root, target_class)\n",
    "            for root_dir, _, file_names in os.walk(target_dir):\n",
    "                for file_name in file_names:\n",
    "                    if file_name.endswith('.wav') or file_name.endswith('.mp3') or file_name.endswith('.ogg'):\n",
    "                        file_path = os.path.join(root_dir, file_name)\n",
    "                        samples.append((file_path, class_index))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path, class_index = self.samples[idx]\n",
    "        # Load the audio file and preprocess\n",
    "        waveform, _ = load(audio_path)\n",
    "        waveform = self._preprocess_audio(waveform)\n",
    "        return waveform, class_index\n",
    "\n",
    "    def _preprocess_audio(self, waveform):\n",
    "        waveform = waveform.numpy()[0]  # Convert tensor to numpy array\n",
    "        max_len = 64600\n",
    "        if waveform.shape[0] >= max_len:\n",
    "            return waveform[:max_len]\n",
    "        else:\n",
    "            num_repeats = int(max_len / waveform.shape[0]) + 1\n",
    "            padded_waveform = np.tile(waveform, (1, num_repeats))[:, :max_len][0]\n",
    "            return padded_waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory where your data is stored\n",
    "root = \"./for-2seconds\"  # Replace this with the path to your data folder\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = AudioDataset(root=os.path.join(root, \"training\"))\n",
    "test_dataset = AudioDataset(root=os.path.join(root, \"testing\"))\n",
    "validation_dataset = AudioDataset(root=os.path.join(root, \"validation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/13956 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Data shape: torch.Size([1, 64600])\n",
      "Target shape: torch.Size([1])\n",
      "Data sample: tensor([-0.0628, -0.0626, -0.0641,  ...,  0.1205,  0.1102,  0.0983])\n",
      "Target sample: tensor(0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the train_loader to inspect the data with tqdm progress bar\n",
    "for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "    print(\"Batch:\", batch_idx)\n",
    "    print(\"Data shape:\", data.shape)  # Shape of the input data tensor\n",
    "    print(\"Target shape:\", target.shape)  # Shape of the target tensor\n",
    "    print(\"Data sample:\", data[0])  # Print the first data sample in the batch\n",
    "    print(\"Target sample:\", target[0])  # Print the target label of the first sample\n",
    "    break  # Break after printing the first batch to keep the output concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (ssl_model): SSLModel(\n",
       "      (model): Wav2Vec2Model(\n",
       "        (feature_extractor): ConvFeatureExtractionModel(\n",
       "          (conv_layers): ModuleList(\n",
       "            (0): Sequential(\n",
       "              (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "            (2): Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "            (3): Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "            (4): Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "            (5): Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "            (6): Sequential(\n",
       "              (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Sequential(\n",
       "                (0): TransposeLast()\n",
       "                (1): Fp32LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                (2): TransposeLast()\n",
       "              )\n",
       "              (3): GELU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_extract_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "        (dropout_features): Dropout(p=0.0, inplace=False)\n",
       "        (quantizer): GumbelVectorQuantizer(\n",
       "          (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "        )\n",
       "        (project_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (encoder): TransformerEncoder(\n",
       "          (pos_conv): Sequential(\n",
       "            (0): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "            (1): SamePad()\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (layers): ModuleList(\n",
       "            (0): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (10): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (11): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (12): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (13): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (14): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (15): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (16): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (17): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (18): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (19): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (20): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (21): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (22): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (23): TransformerSentenceEncoderLayer(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (dropout_module): FairseqDropout()\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (dropout1): Dropout(p=0.0, inplace=False)\n",
       "              (dropout2): Dropout(p=0.0, inplace=False)\n",
       "              (dropout3): Dropout(p=0.0, inplace=False)\n",
       "              (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (final_proj): Linear(in_features=1024, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (LL): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (first_bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (first_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (drop): Dropout(p=0.5, inplace=True)\n",
       "    (drop_way): Dropout(p=0.2, inplace=True)\n",
       "    (selu): SELU(inplace=True)\n",
       "    (encoder): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (conv1): Conv2d(1, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(1, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "          (conv_downsample): Conv2d(32, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Residual_block(\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (selu): SELU(inplace=True)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(2, 3), stride=(1, 1), padding=(0, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): SELU(inplace=True)\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (GAT_layer_S): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (GAT_layer_T): GraphAttentionLayer(\n",
       "      (att_proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST11): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST12): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST21): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (proj_type2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (att_proj): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (HtrgGAT_layer_ST22): HtrgGraphAttentionLayer(\n",
       "      (proj_type1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_type2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (att_projM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_att): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_with_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (proj_without_attM): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (bn): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (input_drop): Dropout(p=0.2, inplace=False)\n",
       "      (act): SELU(inplace=True)\n",
       "    )\n",
       "    (pool_S): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_T): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=64, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT1): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hS2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (pool_hT2): GraphPool(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (proj): Linear(in_features=32, out_features=1, bias=True)\n",
       "      (drop): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (out_layer): Linear(in_features=160, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Load the SSL W2V model trained for LA and DF tracks\n",
    "from model import Model\n",
    "\n",
    "model = Model(None, device=device)\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.load_state_dict(torch.load('/mnt/c/Users/Manish/Desktop/SpeechAssign/SSL_Anti-spoofing/Best_LA_model_for_DF.pth'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7339, -3.6386]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_loader, model, lr, optimizer, device):\n",
    "    running_loss = 0.0\n",
    "    num_total = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # Set objective (Loss) functions\n",
    "    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "    \n",
    "    # Initialize tqdm with the length of the train_loader\n",
    "    progress_bar = tqdm(train_loader, desc='Training', leave=False)\n",
    "    \n",
    "    for batch_x, batch_y in progress_bar:\n",
    "        batch_size = batch_x.size(0)\n",
    "        num_total += batch_size\n",
    "        \n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        batch_out = model(batch_x)\n",
    "        \n",
    "        # Compute loss\n",
    "        batch_loss = criterion(batch_out, batch_y)\n",
    "        \n",
    "        running_loss += batch_loss.item() * batch_size\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(loss=running_loss / num_batches)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Compute average loss\n",
    "    running_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    return running_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/13956 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3cc4d5d24304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Run training epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Print training loss for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d59b53d3a74a>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, model, lr, optimizer, device)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/speech/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/speech/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling `cublasSgemmStridedBatched( handle, opa, opb, m, n, k, &alpha, a, lda, stridea, b, ldb, strideb, &beta, c, ldc, stridec, num_batches)`"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Run training epoch\n",
    "    train_loss = train_epoch(train_loader, model, lr, optimizer, device)\n",
    "    \n",
    "    # Print training loss for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
