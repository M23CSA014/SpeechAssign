{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manish/miniconda3/envs/speech/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#GPU device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'                  \n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# Load the SSL W2V model trained for LA and DF tracks\n",
    "from model import Model\n",
    "\n",
    "model = Model(None, device=device)\n",
    "model = nn.DataParallel(model).to(device)\n",
    "model.load_state_dict(torch.load('/mnt/c/Users/Manish/Desktop/SpeechAssign/SSL_Anti-spoofing/model.pth'))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, max_len=64600):\n",
    "    x_len = x.shape[0]\n",
    "    if x_len >= max_len:\n",
    "        return x[:max_len]\n",
    "    # need to pad\n",
    "    num_repeats = int(max_len / x_len)+1\n",
    "    padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n",
    "    return padded_x\t\n",
    "\n",
    "# Define a function to preprocess the audio samples\n",
    "def preprocess_audio(audio_path):\n",
    "    # Check file extension\n",
    "    _, ext = os.path.splitext(audio_path)\n",
    "    if ext.lower() not in ('.mp3', '.wav'):\n",
    "        # Skip processing if file extension is not .mp3 or .wav\n",
    "        return None\n",
    "    \n",
    "    # Load the audio file and extract features\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "    audio = pad(audio)\n",
    "    # Here you can apply further preprocessing if needed, e.g., feature extraction\n",
    "    return audio\n",
    "\n",
    "\n",
    "# Define paths to real and fake audio samples\n",
    "real_audio_dir = r\"/mnt/c/Users/Manish/Desktop/SpeechAssign/SSL_Anti-spoofing/Dataset1/Dataset_Speech_Assignment/Real\"\n",
    "fake_audio_dir = r\"/mnt/c/Users/Manish/Desktop/SpeechAssign/SSL_Anti-spoofing/Dataset1/Dataset_Speech_Assignment/Fake\"\n",
    "\n",
    "# Collect paths to real and fake audio files\n",
    "real_audio_paths = [os.path.join(real_audio_dir, filename) for filename in os.listdir(real_audio_dir)]\n",
    "fake_audio_paths = [os.path.join(fake_audio_dir, filename) for filename in os.listdir(fake_audio_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Collect predictions and ground truth labels\n",
    "predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "# Use tqdm to add a progress bar\n",
    "for audio_path in tqdm(real_audio_paths + fake_audio_paths):\n",
    "    processed_audio = preprocess_audio(audio_path)\n",
    "    \n",
    "    # Skip processing if preprocess_audio returns None\n",
    "    if processed_audio is None:\n",
    "        continue\n",
    "    \n",
    "    processed_audio_tensor = torch.tensor(processed_audio, dtype=torch.float32).unsqueeze(0)\n",
    "    print(processed_audio_tensor.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(processed_audio_tensor)\n",
    "        # Move the tensor from CUDA device to CPU\n",
    "        output_cpu = output.cpu()\n",
    "\n",
    "        # Extract the second value (index 1) and convert it to a Python scalar\n",
    "        prediction = output_cpu[0][1].item()\n",
    "        \n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # Add ground truth label\n",
    "    if audio_path in real_audio_paths:\n",
    "        ground_truth.append(0)  # 0 for real\n",
    "    else:\n",
    "        ground_truth.append(1)  # 1 for fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(ground_truth, predictions)\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(ground_truth, predictions)\n",
    "\n",
    "# Find the point on the ROC curve where FPR equals 1 - TPR\n",
    "eer = 1.0\n",
    "for i in range(len(fpr)):\n",
    "    if fpr[i] >= 1 - tpr[i]:\n",
    "        eer = fpr[i]\n",
    "        break\n",
    "\n",
    "# Analyze the performance of the model\n",
    "print(\"AUC:\", auc_score)\n",
    "print(\"EER:\", eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
